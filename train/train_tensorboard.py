# å¯¼å…¥å¿…è¦çš„åº“
from unsloth import FastVisionModel
import torch
import os
from datetime import datetime
import threading
from transformers import TrainerCallback

# è®¾ç½®TensorBoardæ—¥å¿—ç›®å½•
log_dir=f"runs/train_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
os.makedirs(log_dir,exist_ok=True)

# å¯¼å…¥TensorBoard
from torch.utils.tensorboard import SummaryWriter
import psutil
import GPUtil
import time

# å…¨å±€å˜é‡ç”¨äºç¡¬ä»¶ç›‘æ§
monitoring_active=True

# åˆ›å»ºTensorBoardå†™å…¥å™¨
writer=SummaryWriter(log_dir=log_dir)


# ç›‘æ§ç¡¬ä»¶ä¿¡æ¯çš„å‡½æ•°
def log_hardware_metrics(step):
    try:
        # CPUä½¿ç”¨ç‡ï¼ˆæ¯ä¸ªæ ¸å¿ƒå’Œæ€»ä½“ï¼‰
        cpu_percent=psutil.cpu_percent(interval=1)
        cpu_percent_per_core=psutil.cpu_percent(interval=1,percpu=True)

        writer.add_scalar('Hardware/CPU_Usage_Total',cpu_percent,step)
        # for i, core_usage in enumerate(cpu_percent_per_core):
        #    writer.add_scalar(f'Hardware/CPU_Core_{i}_Usage', core_usage, step)

        # CPUé¢‘ç‡
        try:
            cpu_freq=psutil.cpu_freq()
            if cpu_freq:
                writer.add_scalar('Hardware/CPU_Frequency_MHz',cpu_freq.current,step)
                writer.add_scalar('Hardware/CPU_Frequency_Min_MHz',cpu_freq.min,step)
                writer.add_scalar('Hardware/CPU_Frequency_Max_MHz',cpu_freq.max,step)
        except:
            pass

        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory=psutil.virtual_memory()
        writer.add_scalar('Hardware/Memory_Usage_GB',memory.used / (1024 ** 3),step)
        writer.add_scalar('Hardware/Memory_Available_GB',memory.available / (1024 ** 3),step)
        writer.add_scalar('Hardware/Memory_Total_GB',memory.total / (1024 ** 3),step)
        writer.add_scalar('Hardware/Memory_Percent',memory.percent,step)

        # äº¤æ¢å†…å­˜
        swap=psutil.swap_memory()
        writer.add_scalar('Hardware/Swap_Usage_GB',swap.used / (1024 ** 3),step)
        writer.add_scalar('Hardware/Swap_Total_GB',swap.total / (1024 ** 3),step)
        writer.add_scalar('Hardware/Swap_Percent',swap.percent,step)

        # ç£ç›˜IO
        disk_io=psutil.disk_io_counters()
        if disk_io:
            writer.add_scalar('Hardware/Disk_Read_Bytes_MB',disk_io.read_bytes / (1024 ** 2),step)
            writer.add_scalar('Hardware/Disk_Write_Bytes_MB',disk_io.write_bytes / (1024 ** 2),step)
            writer.add_scalar('Hardware/Disk_Read_Count',disk_io.read_count,step)
            writer.add_scalar('Hardware/Disk_Write_Count',disk_io.write_count,step)

        # ç½‘ç»œIO
        net_io=psutil.net_io_counters()
        writer.add_scalar('Hardware/Network_Received_Bytes_MB',net_io.bytes_recv / (1024 ** 2),step)
        writer.add_scalar('Hardware/Network_Sent_Bytes_MB',net_io.bytes_sent / (1024 ** 2),step)

        # GPUä½¿ç”¨æƒ…å†µ
        try:
            gpus=GPUtil.getGPUs()
            for i,gpu in enumerate(gpus):
                writer.add_scalar(f'Hardware/GPU_{i}_Usage_Percent',gpu.load * 100,step)
                writer.add_scalar(f'Hardware/GPU_{i}_Memory_Used_MB',gpu.memoryUsed,step)
                writer.add_scalar(f'Hardware/GPU_{i}_Memory_Total_MB',gpu.memoryTotal,step)
                writer.add_scalar(f'Hardware/GPU_{i}_Memory_Percent',gpu.memoryUtil * 100,step)
                writer.add_scalar(f'Hardware/GPU_{i}_Temperature_C',gpu.temperature,step)

                # GPUåŠŸç‡ï¼ˆå¦‚æœæ”¯æŒï¼‰
                if hasattr(gpu,'powerDraw'):
                    writer.add_scalar(f'Hardware/GPU_{i}_Power_W',gpu.powerDraw,step)

        except Exception as e:
            print(f"æ— æ³•è·å–GPUä¿¡æ¯: {e}")

        # è¿›ç¨‹çº§åˆ«çš„å†…å­˜ä½¿ç”¨
        process=psutil.Process()
        process_memory=process.memory_info()
        writer.add_scalar('Process/RSS_MB',process_memory.rss / (1024 ** 2),step)
        writer.add_scalar('Process/VMS_MB',process_memory.vms / (1024 ** 2),step)

        # è¿›ç¨‹CPUä½¿ç”¨ç‡
        writer.add_scalar('Process/CPU_Percent',process.cpu_percent(),step)

        print(f"ç¡¬ä»¶ç›‘æ§å®Œæˆ - æ­¥éª¤: {step}")

    except Exception as e:
        print(f"ç¡¬ä»¶ç›‘æ§å‡ºé”™: {e}")


# ç¡¬ä»¶ç›‘æ§çº¿ç¨‹å‡½æ•°
def hardware_monitoring_thread():
    """ç‹¬ç«‹çš„ç¡¬ä»¶ç›‘æ§çº¿ç¨‹"""
    step=0
    while monitoring_active:
        try:
            log_hardware_metrics(step)
            step+=1
            time.sleep(5)  # æ¯5ç§’è®°å½•ä¸€æ¬¡ç¡¬ä»¶ä¿¡æ¯
        except Exception as e:
            print(f"ç¡¬ä»¶ç›‘æ§çº¿ç¨‹å‡ºé”™: {e}")
            time.sleep(1)


# å¯åŠ¨ç¡¬ä»¶ç›‘æ§çº¿ç¨‹
monitor_thread=threading.Thread(target=hardware_monitoring_thread,daemon=True)
monitor_thread.start()

# åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
model,tokenizer=FastVisionModel.from_pretrained(
    model_name="/root/autodl-tmp/models/Qwen/Qwen2.5-VL-7B-Instruct",  # æŒ‡æ˜è¦å»åŠ è½½çš„æ¨¡å‹åœ¨æœ¬åœ°çš„è·¯å¾„
    load_in_4bit=False,  # ä½¿ç”¨ 4bit é‡åŒ–å‡å°‘å†…å­˜çš„ä½¿ç”¨ã€‚ é»˜è®¤æ˜¯ Falseï¼Œåˆ™ä¼šä½¿ç”¨ 16bit è®­ç»ƒ
    use_gradient_checkpointing="unsloth"  # è®¾ç½®ä¸º True æˆ–è€… è®¾ç½®ä¸º "unsloth" æ”¯æŒæ›´é•¿çš„ä¸Šä¸‹æ–‡
)

model=FastVisionModel.get_peft_model(
    model,

    # é¦–å…ˆæ•´ä½“ä¸Šè®¾ç½®å¤šæ¨¡æ€å¤§æ¨¡å‹ä¸­å“ªäº›å±‚å»è¿›è¡ŒLoRAå¾®è°ƒ
    finetune_vision_layers=False,  # æ˜¯å¦å¾®è°ƒè§†è§‰ç›¸å…³å±‚
    finetune_language_layers=True,  # æ˜¯å¦å¾®è°ƒè¯­è¨€æ¨¡å‹ç›¸å…³çš„å±‚
    finetune_attention_modules=True,  # æ˜¯å¦å¾®è°ƒæ³¨æ„åŠ›ç›¸å…³å±‚
    finetune_mlp_modules=True,  # æ˜¯å¦å¾®è°ƒ MLP å±‚ï¼Œå½±å“éªŒè¯é›†å‡†ç¡®ç‡

    # LoRA ç›¸å…³æ ¸å¿ƒå‚æ•°
    r=16,  # rankå€¼ï¼Œè¶Šå¤§è°ƒæ•´çš„å‚æ•°å°±ä¼šè¶Šå¤šï¼Œå½“ç„¶ä¹Ÿä¼šè¶Šå‡†ï¼›ä½†å®¹æ˜“è¿‡æ‹Ÿåˆ
    lora_alpha=16,  # æ¨èè‡³å°‘ alpha==rï¼Œå½±å“è®­ç»ƒè¿‡ç¨‹ä¸­æ”¶æ•›çš„é€Ÿåº¦å’Œæ•ˆæœ
    lora_dropout=0,  # dropout ratio ç”¨äºæ”¾ç½®è¿‡æ‹Ÿåˆçš„æ‰‹æ®µ
    bias="none",  # æˆªè·é¡¹ï¼Œæ˜¯å¦æ·»åŠ åç½®é¡¹

    # é…ç½®å…¶å®ƒçš„ä¸€äº›è¶…å‚æ•°
    # random_state = 3407, # éšæœºç§å­ï¼Œå¦‚æœä¸å»è®¾ç½®ï¼Œé‚£ä¹ˆæœ¬åçš„æœ¬è´¨å°±æ˜¯éšæœºç§å­è¿™ä¸ªæ•°å€¼æœ¬èº«ä¼šæ˜¯ä¸ªéšæœºæ•°ï¼Œç¡®ä¿ä½¿ç”¨å…·å¤‡å¯é‡å¤æ€§
    use_rslora=False,  # å¦‚æœè®¾ç½®æˆTrueï¼Œå®ƒå°±ä¼šå»ä½¿ç”¨ rank stabilized LoRA
    loftq_config=None,  # å…³äº LoftQ é…ç½®ï¼Œç”¨äºé‡åŒ–
    # target_modules = "all-linear", # å¯é€‰é¡¹ï¼Œå¯ä»¥æŒ‡å¯¼éœ€è¦åº”ç”¨LoRAçš„å…·ä½“æ¨¡å—æ˜¯å“ªäº›
)

from datasets import load_dataset,Dataset
from sklearn.model_selection import train_test_split
# å‡è®¾ä½ å·²åŠ è½½ train_dataset
dataset = load_dataset("./data/", split="train")
test_dataset = load_dataset("./data/", split="test")

# è½¬ä¸º list æˆ– Dataset å¯¹è±¡ä¾¿äºåˆ’åˆ†
if isinstance(dataset, list):
    # å¦‚æœå·²ç»æ˜¯ list
    train_val_split = Dataset.from_list(dataset).train_test_split(test_size=0.1, seed=42) #0.1 æ•°æ®é›†çš„10%ä½œä¸ºéªŒè¯é›†ï¼Œå‰©ä½™çš„90%ä½œä¸ºè®­ç»ƒé›† 42 éšæœºç§å­ ç¡®ä¿æ¯æ¬¡è¿è¡Œä»£ç æ—¶æ•°æ®é›†çš„åˆ’åˆ†æ–¹å¼ç›¸åŒï¼Œä½¿ç»“æœå¯é‡ç°
else:
    # å¦‚æœæ˜¯ Hugging Face Dataset
    train_val_split = dataset.train_test_split(test_size=0.1, seed=42)

train_dataset = train_val_split['train'] # è®­ç»ƒé›†
val_dataset = train_val_split['test']  # éªŒè¯é›†

instruction="ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ”¾å°„ç§‘åŒ»ç”Ÿã€‚è¯·å‡†ç¡®æè¿°ä½ åœ¨å›¾ç‰‡ä¸­çœ‹åˆ°çš„å†…å®¹ã€‚"
def convert_to_conversation(sample):
    conversation=[
        {
            "role":"user",
            "content":[{"type":"text","text":instruction},{"type":"image","image":sample['image']}]
        },
        {
            "role":"assistant",
            "content":[{"type":"text","text":sample['caption']}]
        }
    ]
    return {"messages":conversation}

converted_train_dataset = [convert_to_conversation(sample) for sample in train_dataset]
converted_val_dataset = [convert_to_conversation(sample) for sample in val_dataset]
converted_test_dataset = [convert_to_conversation(sample) for sample in test_dataset]  # æœ€åè¯„ä¼°ç”¨
# converted_dataset=[convert_to_conversation(sample) for sample in dataset]

# å¯¼å…¥å¿…è¦æ¨¡å—
from unsloth import is_bf16_supported
from unsloth.trainer import UnslothVisionDataCollator
from trl import SFTTrainer,SFTConfig

class ValidationCallback(TrainerCallback):
    def __init__(self, trainer, val_dataset, eval_steps=5, metric="loss"):
        self.trainer = trainer
        self.val_dataset = val_dataset
        self.eval_steps = eval_steps
        self.best_metric = float('inf') if metric == "loss" else 0.0
        self.best_step = 0
        self.metric = metric  # 'loss' or 'accuracy' etc.

    def on_step_end(self, args, state, control, **kwargs):
        if state.global_step % self.eval_steps == 0:
            print(f"\n>>> æ­¥éª¤ {state.global_step}: å¼€å§‹éªŒè¯é›†è¯„ä¼°...")

            # è¯„ä¼°éªŒè¯é›†
            eval_results = self.trainer.evaluate(eval_dataset=self.val_dataset)
            val_loss = eval_results["eval_loss"]

            # å†™å…¥ TensorBoard
            writer.add_scalar("Validation/Loss", val_loss, state.global_step)

            print(f"éªŒè¯æŸå¤±: {val_loss:.6f}")

            # åˆ¤æ–­æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
            is_best = False
            if self.metric == "loss":
                if val_loss < self.best_metric:
                    self.best_metric = val_loss
                    self.best_step = state.global_step
                    is_best = True
                    print(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹ï¼æ­¥éª¤: {state.global_step}, éªŒè¯æŸå¤±: {val_loss:.6f}")

            # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œä¿å­˜
            if is_best:
                save_path = f"./checkpoints/best_model_step_{state.global_step}"
                self.trainer.save_model(save_path)
                print(f"âœ… æœ€ä½³æ¨¡å‹å·²ä¿å­˜è‡³: {save_path}")

            # å¯é€‰ï¼šè®°å½•åˆ° TensorBoard
            writer.add_scalar("Validation/Best_Loss", self.best_metric, state.global_step)

FastVisionModel.for_training(model)  # åˆ‡æ¢è®­ç»ƒæ¨¡å¼ï¼
# é…ç½®è®­ç»ƒå™¨
trainer=SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    data_collator=UnslothVisionDataCollator(model,tokenizer),  # å¿…é¡»è¦è®¾ç½®çš„
    train_dataset=converted_train_dataset,
    eval_dataset=converted_val_dataset,
    args=SFTConfig(
        # åŸºç¡€è®­ç»ƒçš„ç›¸å…³å‚æ•°
        per_device_train_batch_size=2,  # å¯¹åº”æ¯ä¸ªæ˜¾å¡çš„æ‰¹æ¬¡åŒ…å«çš„æ ·æœ¬æ•°
        gradient_accumulation_steps=4,  # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼Œç›®çš„å°±æ˜¯èŠ‚çœæ˜¾å­˜ç©ºé—´ï¼Œç”¨æ—¶é—´æ¢ç©ºé—´äº†
        max_steps=50,  # æœ€å¤§è®­ç»ƒæ¬¡æ•°ï¼Œå½“æˆ‘ä»¬ç»™å®š max_stepsåï¼Œå®ƒä¼šè¦†ç›– num_train_epochs
        # num_train_epochs = 3,           # å®Œæ•´è®­ç»ƒä¸€æ¬¡ï¼ŒæŠŠè®­ç»ƒæ ·æœ¬äº¤ç»™æ¨¡å‹å­¦ä¹ ä¸€é
        save_steps=5,
        save_total_limit=10,
        # save_every_n_epochs_equivalent = 1,  # ç›¸å½“äºæ¯â€œ1è½®â€ä¿å­˜ä¸€æ¬¡ï¼ˆå³ä½¿ä½ ç”¨çš„æ˜¯ max_stepsï¼‰
        # save_steps = max(1, max_steps // 10),  # è‡³å°‘ä¿å­˜1æ¬¡ï¼Œæœ€å¤š10æ¬¡
        output_dir = "./checkpoints",
        # ä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡ç›¸å…³å‚æ•°è®¾ç½®
        learning_rate=2e-4,  # å­¦ä¹ ç‡ è¶Šå°è¶Šç¨³ï¼Œä½†æ˜¯å¯èƒ½å­¦ä¸åˆ°ä¸œè¥¿ï¼›è¶Šå¤§ å­¦ä¹ è¶Šå¿«ï¼Œä½†å®¹æ˜“â€œè·³è¿‡æœ€ä¼˜è§£â€
        warmup_steps=5,  # é¢„çƒ­æ­¥æ•°/é¢„çƒ­è¿­ä»£æ¬¡æ•°
        lr_scheduler_type="linear",  # çº¿æ€§å­¦ä¹ ç‡è°ƒæ•´å™¨
        fp16=not is_bf16_supported(),
        bf16=is_bf16_supported(),

        # Adam ä¼˜åŒ–å™¨æœ¬èº«ç»“åˆåŠ¨é‡å’Œè‡ªé€‚åº”å­¦ä¹ ç‡ï¼Œèƒ½å¤Ÿé€‚åº”ç¨€ç–æ¢¯åº¦ï¼Œåœ¨è®¸å¤šä»»åŠ¡ä¸Šè¡¨ç°éƒ½å¾ˆå‡ºè‰²ã€‚
        # AdamW 8-bit æ˜¯ AdamW ä¼˜åŒ–å™¨çš„ä¸€ç§ä½ç²¾åº¦å˜ä½“ï¼Œç›®çš„é™ä½å†…å­˜æ¶ˆè€—å’Œè®¡ç®—æˆæœ¬ã€‚
        # ä½ç²¾åº¦è®¡ç®—ï¼šæ ‡å‡†çš„æ˜¯ 32bit æµ®ç‚¹æ•°è¿ç®—ï¼Œæ¯ä¸ªæ•°å€¼å ç”¨32ä½ï¼Œ8bitæ˜¯ä¸æ˜¯ç›¸å½“äºä»…æ˜¯åŸæ¥çš„1/4ï¼Œè¿™ç§ä½ç²¾åº¦è®­ç»ƒæ–¹æ³•ç‰¹åˆ«é€‚åˆå†…å­˜å—é™çš„ç¯å¢ƒå»è®­ç»ƒå¤§æ¨¡å‹ï¼Œ
        # ä¾‹å¦‚åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæˆ–è€…éœ€è¦è®­ç»ƒç‰¹åˆ«å¤§çš„å¤§æ¨¡å‹çš„æ—¶å€™ã€‚
        optim="adamw_8bit",  # ä½¿ç”¨ 8bit AdamW ä¼˜åŒ–å™¨æ¥è°ƒæ•´å‚æ•°
        weight_decay=0.01,  # æƒé‡è¡°å‡ï¼Œå…¶å®æœ¬è´¨ä¸Šæ˜¯å’Œæ­£åˆ™é¡¹æœ‰å…³ç³»çš„ L1/L2

        # æ·»åŠ æ—¥å¿—è®°å½•å›è°ƒ
        logging_dir=log_dir,
        logging_steps=1,
        report_to=["tensorboard"],
    )
)
validation_callback = ValidationCallback(trainer, converted_val_dataset, eval_steps=5)
trainer.add_callback(validation_callback)

import torch._dynamo.config

# æé«˜ç¼“å­˜å¤§å°é™åˆ¶ï¼ˆé»˜è®¤å¯èƒ½æ˜¯ 64ï¼‰
torch._dynamo.config.cache_size_limit=128

# å…³é—­ä¸¥æ ¼æ¨¡å¼ï¼ˆå…è®¸æ›´å¤šé‡æ–°ç¼–è¯‘ï¼‰
torch._dynamo.config.suppress_errors=True

try:
    trainer_stats=trainer.train()

finally:
    print("ğŸ† æœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°ï¼ˆä»…æ­¤ä¸€æ¬¡ï¼ï¼‰")
    test_results=trainer.evaluate(eval_dataset=converted_test_dataset)
    for k,v in test_results.items():
        print(f"{k}: {v:.6f}")
        writer.add_scalar(f"Final_Test/{k}",v,0)
    # æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°ï¼ŒLoRA
    model.save_pretrained("lora_model")
    tokenizer.save_pretrained("lora_model")

    # ä¿å­˜åˆå¹¶çš„æ¨¡å‹
    # model.save_pretrained_merged("merged_model",tokenizer,save_method="merged_16bit")

    # åœæ­¢ç›‘æ§çº¿ç¨‹
    monitoring_active=False
    if monitor_thread.is_alive():
        monitor_thread.join(timeout=2.0)

    # å…³é—­TensorBoardå†™å…¥å™¨
    writer.close()
    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼æœ€ä½³æ¨¡å‹æ­¥éª¤: {getattr(validation_callback,'best_step','N/A')}")
    print(f"è®­ç»ƒå®Œæˆï¼ŒTensorBoardæ—¥å¿—ä¿å­˜åœ¨: {log_dir}")
    print("è¦å¯åŠ¨TensorBoardï¼Œè¯·è¿è¡Œ: tensorboard --logdir=runs/")