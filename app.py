import base64
import io
import uuid
import gradio as gr
from PIL import Image
from langchain_community.chat_message_histories import SQLChatMessageHistory
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableWithMessageHistory
from model import create_multiModal_llm,AVAILABLE_MODELS,MODEL_CONFIGS

DEFAULT_MODEL = AVAILABLE_MODELS[0]
# å…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨å½“å‰æ¨¡å‹å®ä¾‹å’Œé…ç½®
current_multiModal_llm = create_multiModal_llm(DEFAULT_MODEL)
current_model_name = DEFAULT_MODEL

# è·å–é»˜è®¤æ¨¡å‹çš„ç«¯å£ä¿¡æ¯
default_config = MODEL_CONFIGS.get(DEFAULT_MODEL)
default_port = default_config["base_url"].split(":")[2].split("/")[0]  # ä»URLæå–ç«¯å£
default_status = f"âœ… å½“å‰æ¨¡å‹: {DEFAULT_MODEL} (ç«¯å£: {default_port})"

prompt = ChatPromptTemplate.from_messages(
    [
        ('system', "ä½ æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€AIåŠ©æ‰‹ï¼Œå¯ä»¥å¤„ç†æ–‡æœ¬ã€éŸ³é¢‘å’Œå›¾åƒè¾“å…¥"),
        MessagesPlaceholder(variable_name="messages"),  # ä»£è¡¨ï¼šå†å²æ¶ˆæ¯ã€‚ è®©å¤§æ¨¡å‹å¯ä»¥ç†è§£ä¸Šä¸‹æ–‡è¯­ä¹‰
    ]
)

chain = prompt | current_multiModal_llm


def get_session_history(session_id: str):
    """ä»å…³ç³»å‹æ•°æ®åº“çš„å†å²æ¶ˆæ¯åˆ—è¡¨ä¸­ è¿”å›å½“å‰ä¼šè¯ çš„æ‰€æœ‰å†å²æ¶ˆæ¯"""
    return SQLChatMessageHistory(
        session_id=session_id,
        connection_string='sqlite:///chat_history.db',
    )


chain_history = RunnableWithMessageHistory(
    chain,
    get_session_history,
)

config = {"configurable": {"session_id": str(uuid.uuid4())}}


def update_model(model_name):
    """æ›´æ–°å½“å‰ä½¿ç”¨çš„æ¨¡å‹ï¼Œå¹¶æ¸…ç©ºèŠå¤©å†å²"""
    global current_multiModal_llm, chain, chain_history, current_model_name, config

    try:
        # åˆ›å»ºæ–°çš„æ¨¡å‹å®ä¾‹
        current_multiModal_llm = create_multiModal_llm(model_name)
        current_model_name = model_name
        model_port = current_multiModal_llm.openai_api_base.split(":")[2].split("/")[0]

        # é‡æ–°æ„å»º chain
        chain = prompt | current_multiModal_llm
        chain_history = RunnableWithMessageHistory(
            chain,
            get_session_history,
        )

        # âœ… ç”Ÿæˆæ–° session_id
        new_session_id = str(uuid.uuid4())
        config = {"configurable": {"session_id": new_session_id}}

        # âœ… ä¸»åŠ¨æ¸…é™¤æ—§ session çš„å†å²è®°å½•ï¼ˆå¯é€‰ï¼Œä½†æ¨èï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œæ¸…é™¤çš„æ˜¯â€œå³å°†è¢«æ›¿æ¢çš„æ—§ sessionâ€ï¼Œä¸æ˜¯æ–° session
        # å¦‚æœä½ æƒ³æ¸…é™¤â€œå½“å‰æ­£åœ¨ä½¿ç”¨çš„ sessionâ€ï¼Œå¯ä»¥ä¿ç•™æ—§ session_id å†æ¸…é™¤
        old_session_id = config["configurable"]["session_id"]  # å®é™…ä¸Šæ˜¯ä¸Šä¸€æ¬¡çš„ï¼Œè¿™é‡Œä»…ä¸ºç¤ºæ„
        # æ›´å®‰å…¨çš„åšæ³•ï¼šåœ¨åˆ‡æ¢å‰è®°å½•æ—§ session_idï¼Œç„¶åæ¸…é™¤å®ƒ

        # âœ… æ›´ä¸¥è°¨çš„åšæ³•ï¼šå…ˆè®°å½•æ—§ sessionï¼Œå†æ¢æ–° sessionï¼Œå†æ¸…é™¤æ—§ session
        old_session_id = config["configurable"]["session_id"] if "session_id" in config.get("configurable", {}) else None
        config = {"configurable": {"session_id": new_session_id}}  # æ¢æ–°ä¼šè¯

        if old_session_id:
            old_history = get_session_history(old_session_id)
            old_history.clear()  # âœ… å½»åº•ä»æ•°æ®åº“åˆ é™¤æ—§å†å²
            print(f"ğŸ§¹ å·²æ¸…é™¤æ—§ä¼šè¯ {old_session_id} çš„å†å²è®°å½•")

        # âœ… è¿”å›ä¸¤ä¸ªå€¼ï¼šçŠ¶æ€æ¶ˆæ¯ + ç©ºèŠå¤©è®°å½•
        return f"âœ… æ¨¡å‹å·²åˆ‡æ¢åˆ°: {model_name} (ç«¯å£: {model_port})ï¼Œå†å²å·²æ¸…ç©º", []

    except Exception as e:
        return f"âŒ æ¨¡å‹åˆ‡æ¢å¤±è´¥: {str(e)}", []

# è¯­éŸ³å¤„ç†å‡½æ•° =====
def transcribe_audio(audio_path):
    """ä½¿ç”¨Base64å¤„ç†è¯­éŸ³è½¬ä¸º"""

    # ç›®å‰å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼š æ”¯æŒä¸¤ä¸ªä¼ å‚æ–¹å¼ï¼Œ1ã€base64ï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼ˆæœ¬åœ°ï¼‰ã€‚2ã€ç½‘ç»œè®¿é—®çš„urlåœ°å€ï¼ˆå¤–ç½‘çš„æœåŠ¡å™¨ä¸Šï¼‰ http://sxxxx.com/11.mp3
    try:
        with open(audio_path, 'rb') as audio_file:
            audio_data = base64.b64encode(audio_file.read()).decode('utf-8')
        audio_message = {  # æŠŠéŸ³é¢‘æ–‡ä»¶ï¼Œå°è£…æˆä¸€æ¡æ¶ˆæ¯
            "type": "audio_url",
            "audio_url": {
                "url": f"data:audio/wav;base64,{audio_data}",
                "duration": 30  # å•ä½ï¼šç§’ï¼ˆå¸®åŠ©æ¨¡å‹ä¼˜åŒ–å¤„ç†ï¼‰
            }
        }

        return audio_message
    except Exception as e:
        print(e)
        return {}


def transcribe_image(image_path):
    """
    å°†ä»»æ„æ ¼å¼çš„å›¾ç‰‡è½¬æ¢ä¸ºbase64ç¼–ç çš„data URL
    :param image_path: å›¾ç‰‡è·¯å¾„
    :return: åŒ…å«base64ç¼–ç çš„å­—å…¸
    """
    with Image.open(image_path) as img:
        # è·å–åŸå§‹å›¾ç‰‡æ ¼å¼ï¼ˆå¦‚JPEG/PNGï¼‰
        img_format = img.format if img.format else 'JPEG'

        buffered = io.BytesIO()
        # ä¿ç•™åŸå§‹æ ¼å¼ï¼ˆé¿å…JPEGå¼ºåˆ¶è½¬æ¢å¯¼è‡´é€æ˜é€šé“ä¸¢å¤±ï¼‰
        img.save(buffered, format=img_format)

        image_data = base64.b64encode(buffered.getvalue()).decode('utf-8')
        return {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/{img_format.lower()};base64,{image_data}",
                "detail": 'low'
            }
        }

def get_last_user_after_assistant(history):
    """åå‘éå†æ‰¾åˆ°æœ€åä¸€ä¸ªassistantçš„ä½ç½®,å¹¶è¿”å›åé¢çš„æ‰€æœ‰useræ¶ˆæ¯"""
    if not history:
        return None
    if history[-1]["role"] == "assistant":
        return None

    last_assistant_idx = -1
    for i in range(len(history) - 1, -1, -1):
        if history[i]["role"] == "assistant":
            last_assistant_idx = i
            break

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°assistant
    if last_assistant_idx == -1:
        return history
    else:
        # ä»assistantä½ç½®å‘åæŸ¥æ‰¾ç¬¬ä¸€ä¸ªuser
        return history[last_assistant_idx + 1:]


def add_message(history, messages):
    """å°†ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©è®°å½•ä¸­"""
    for m in messages['files']:
        print(m)
        history.append({'role': 'user', "content": {'path': m}})
    # å¤„ç†æ–‡æœ¬æ¶ˆæ¯
    if messages["text"] is not None:
        history.append({"role": "user", "content": messages["text"]})
    return history, gr.MultimodalTextbox(value=None, interactive=False)  # è¿”å›æ›´æ–°åçš„å†å²å’Œé‡ç½®çš„è¾“å…¥æ¡†


def submit_messages(history):
    """æäº¤ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯ï¼Œç”Ÿæˆæœºå™¨äººå›å¤"""
    user_messages = get_last_user_after_assistant(history)
    print(user_messages)
    content = []  # HumanMessageçš„å†…å®¹
    if user_messages:
        for x in user_messages:
            if isinstance(x['content'], str):  # æ–‡å­—è¾“å…¥æ¶ˆæ¯
                content.append({'type': 'text', 'text': x['content']})
            elif isinstance(x['content'], tuple):  # å¤šåª’ä½“è¾“å…¥æ¶ˆæ¯
                file_path = x['content'][0]  # å¾—åˆ°å¤šåª’ä½“çš„æ–‡ä»¶è·¯å¾„
                if file_path.endswith('.wav'):  #  è¾“å…¥çš„æ˜¯éŸ³é¢‘æ–‡ä»¶
                    file_message = transcribe_audio(file_path)
                elif file_path.endswith(".jpg") or file_path.endswith(".png") or file_path.endswith(".jpeg"):
                    file_message = transcribe_image(file_path)
                content.append(file_message)
            else:
                pass
    input_message = HumanMessage(content=content)

    resp = chain_history.invoke({'messages': input_message}, config)
    history.append({'role': 'assistant', 'content': resp.content})
    return history

css = '''
#bgc {background-color: #7FFFD4}
.feedback textarea {font-size: 24px !important}
'''
# å¼€å‘ä¸€ä¸ªèŠå¤©æœºå™¨äººçš„Webç•Œé¢
with gr.Blocks(title='åŒ»ç–—å½±åƒAIåŠ©æ‰‹', css=css, theme=gr.themes.Soft()) as app:
    gr.Label('åŒ»ç–—å½±åƒAIåŠ©æ‰‹',container=False)
    # æ¨¡å‹é€‰æ‹©åŒºåŸŸ
    with gr.Row(equal_height=True,variant="panel"):
        with gr.Column(scale=1):
            model_dropdown=gr.Dropdown(
                choices=AVAILABLE_MODELS,
                value=DEFAULT_MODEL,
                label="é€‰æ‹©æ¨¡å‹",
                interactive=True,
                elem_classes="model-selector"
            )
        with gr.Column(scale=2):
            model_status=gr.Textbox(
                label="å½“å‰æ¨¡å‹çŠ¶æ€",
                value=default_status,
                interactive=False,
                show_label=True
            )
    # èŠå¤©å†å²è®°å½•çš„ç»„ä»¶
    chatbot = gr.Chatbot(type='messages',
                         height=500,
                         avatar_images=("./images/chat.png","./images/robot.png"),  # è®¾ç½®é»˜è®¤ç”¨æˆ·å’ŒåŠ©æ‰‹å¤´åƒ
                         show_label=False,
                         bubble_full_width=False)
    # æ¨¡å‹åˆ‡æ¢äº‹ä»¶
    model_dropdown.change(
        update_model,
        inputs=[model_dropdown],
        outputs=[model_status,chatbot]
    )
    # åˆ›å»ºå¤šæ¨¡æ€è¾“å…¥æ¡†
    chat_input = gr.MultimodalTextbox(
        interactive=True,  # å¯äº¤äº’
        file_types=['image', '.wav', '.mp4'],
        file_count="multiple",  # å…è®¸å¤šæ–‡ä»¶ä¸Šä¼ 
        placeholder="è¯·è¾“å…¥ä¿¡æ¯æˆ–è€…ä¸Šä¼ æ–‡ä»¶...",  # è¾“å…¥æ¡†æç¤ºæ–‡æœ¬
        show_label=False,  # ä¸æ˜¾ç¤ºæ ‡ç­¾
        sources=["microphone", "upload"],  # æ”¯æŒéº¦å…‹é£å’Œæ–‡ä»¶ä¸Šä¼ 
    )

    chat_input.submit(
        add_message,
        [chatbot, chat_input],
        [chatbot, chat_input]
    ).then(
        submit_messages,
        [chatbot],
        [chatbot],
    ).then(  # å›å¤å®Œæˆåé‡æ–°æ¿€æ´»è¾“å…¥æ¡†
        lambda: gr.MultimodalTextbox(interactive=True),  # åŒ¿åå‡½æ•°é‡ç½®è¾“å…¥æ¡†
        None,  # æ— è¾“å…¥
        [chat_input]  # è¾“å‡ºåˆ°è¾“å…¥æ¡†
    )

if __name__ == '__main__':
    app.launch(allowed_paths=['./'])
